# predict.py

import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast
from deep_translator import GoogleTranslator
from langdetect import detect

# ========================
# ADIM 0: Gerekli KÃ¼tÃ¼phanelerin Ä°Ã§e AktarÄ±lmasÄ± ve GPU KontrolÃ¼
# ========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ–¥ï¸ Using device: {device}")

# ========================
# ADIM 1: KaydedilmiÅŸ Modeli ve Tokenizer'Ä± YÃ¼kleme
# ========================
# Modelin kaydedildiÄŸi dizini belirtin (tam yol kullanmak daha saÄŸlÄ±klÄ± olabilir)
model_path = "D:/YAPAY ZEKA MODÃœLLER/trained_model"
model = DistilBertForSequenceClassification.from_pretrained(model_path).to(device)
tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)

# Etiket sÃ¶zlÃ¼ÄŸÃ¼ (model eÄŸitimi sÄ±rasÄ±nda kullanÄ±lan etiketlerin sÄ±rasÄ±)
id2label = {0: "Corporate", 1: "Human Resources", 2: "Other", 3: "Support"}

# Åablon yanÄ±tlar
TEMPLATE_RESPONSES = {
    "Corporate": "Your request has been received. Our relevant department will get back to you as soon as possible.",
    "Human Resources": "Our Human Resources team has reviewed your inquiry and will contact you shortly. Thank you for your interest.",
    "Other": "We have received your message. It will be reviewed and processed accordingly.",
    "Support": "Our support team is evaluating your request and will reach out to you as soon as possible."
}

# ========================
# ADIM 2: process_email() Fonksiyonu (Inference)
# ========================
def process_email(email_text):
    # Gelen e-posta metninin dilini algÄ±la
    src_lang = detect(email_text)
    
    # E-posta metnini Ä°ngilizceye Ã§evir (gerekirse)
    translated_text = email_text if src_lang == "en" else GoogleTranslator(source=src_lang, target="en").translate(email_text)
    
    # Model girdi hazÄ±rlÄ±ÄŸÄ±: Tokenizasyon, truncation, padding
    inputs = tokenizer(translated_text, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
    inputs = {key: value.to(device) for key, value in inputs.items()}
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    predicted_idx = outputs.logits.argmax(dim=-1).item()
    predicted_label = id2label[predicted_idx]
    response_en = TEMPLATE_RESPONSES[predicted_label]
    
    # YanÄ±tÄ±, eÄŸer gerekli ise, orijinal dile Ã§evir
    final_response = response_en if src_lang == "en" else GoogleTranslator(source="en", target=src_lang).translate(response_en)
    return predicted_label, response_en, final_response

# ========================
# ADIM 3: Test ve KullanÄ±cÄ± Girdisi
# ========================
if __name__ == "__main__":
    # Test e-postalarÄ± (farklÄ± dillerde)
    test_emails = [
        "I need support regarding my latest order.",
        "Can you send me the invoice for my last purchase?",
        "SipariÅŸimle ilgili destek istiyorum.",
        "Son satÄ±n alma iÅŸlemimle ilgili faturayÄ± gÃ¶nderebilir misiniz?",
        "Quiero cancelar mi pedido.",
        "Comment puis-je obtenir de l'aide avec mon achat rÃ©cent ?",
    ]
    
    print("\n--- Model Ã‡Ä±ktÄ±larÄ±nÄ± Test Ediyoruz ---\n")
    for email in test_emails:
        label, response_en, response_final = process_email(email)
        print(f"ğŸ“© E-posta: {email}")
        print(f"ğŸ· Tahmin Edilen Kategori: {label}")
        print(f"ğŸ’¬ Ä°ngilizce YanÄ±t: {response_en}")
        print(f"ğŸŒ Orijinal Dilinde YanÄ±t: {response_final}\n")
    
    # Alternatif: KullanÄ±cÄ±dan e-posta metni alarak tahmin yap
    user_input = input("LÃ¼tfen e-posta metnini giriniz: ")
    label, response_en, response_final = process_email(user_input)
    print(f"\nTahmin Edilen Kategori: {label}")
    print(f"YanÄ±t: {response_final}")
