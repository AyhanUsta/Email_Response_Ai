import random
import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np

# ========================
# 1ï¸âƒ£ GPU KullanÄ±m KontrolÃ¼
# ========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ–¥ï¸ Using device: {device}")

# ========================
# 2ï¸âƒ£ EÄŸitilmiÅŸ Modeli ve Tokenizer'Ä± YÃ¼kleme
# ========================
model_path = "D:/YAPAY ZEKA MODÃœLLER/trained_model"  # Modelin kaydedildiÄŸi dizin
tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)
model = DistilBertForSequenceClassification.from_pretrained(model_path).to(device).eval()

# Etiket eÅŸleÅŸmeleri (0: Corporate, 1: Human Resources, 2: Other, 3: Support)
id2label = {0: "Corporate", 1: "Human Resources", 2: "Other", 3: "Support"}

# ========================
# 3ï¸âƒ£ Test Verisi Ãœretimi: Her kategoriden 100 farklÄ± test metni
# ========================

def generate_test_sentences(templates, count):
    """
    Verilen ÅŸablon listesinden rastgele seÃ§ip, her biri sonuna Ã¶rnek numarasÄ± ekleyerek 'count' adet farklÄ± cÃ¼mle Ã¼retir.
    """
    sentences = []
    for i in range(count):
        template = random.choice(templates)
        # Ek varyasyon iÃ§in Ã¶rnek numarasÄ±nÄ± ekliyoruz
        sentence = f"{template} (example {i+1})"
        sentences.append(sentence)
    return sentences

# FarklÄ± ÅŸablonlar tanÄ±mlÄ±yoruz:
corporate_templates = [
    "Could you please send me the invoice for my last purchase?",
    "I need a copy of my invoice for my recent corporate expense.",
    "Please forward the invoice related to my business order."
]

hr_templates = [
    "I would like to inquire about job opportunities in your HR department.",
    "Could you provide more details on human resources openings?",
    "I am interested in pursuing a career in HR at your company."
]

other_templates = [
    "I have a query that does not seem to fit into any of the usual categories.",
    "My question is miscellaneous and cannot be classified under standard labels.",
    "I need information on a matter that is not related to corporate, HR, or support."
]

support_templates = [
    "I need support regarding my recent order.",
    "I require assistance with an issue in my order delivery.",
    "My order has encountered a problem; please help as soon as possible."
]

# Her kategori iÃ§in 100 farklÄ± Ã¶rnek oluÅŸturuyoruz.
corporate_texts = generate_test_sentences(corporate_templates, 100)
hr_texts = generate_test_sentences(hr_templates, 100)
other_texts = generate_test_sentences(other_templates, 100)
support_texts = generate_test_sentences(support_templates, 100)

# TÃ¼m metinleri birleÅŸtiriyoruz: toplam 400 Ã¶rnek
test_texts = corporate_texts + hr_texts + other_texts + support_texts
# GerÃ§ek etiketler: Ã¶nce 100 adet 0, ardÄ±ndan 100 adet 1, 100 adet 2, son olarak 100 adet 3
test_labels = [0]*100 + [1]*100 + [2]*100 + [3]*100

# ========================
# 4ï¸âƒ£ Model Tahminlerinin HesaplanmasÄ±
# ========================
# Test metinlerini tokenleÅŸtir
inputs = tokenizer(test_texts, return_tensors="pt", padding=True, truncation=True, max_length=512)
inputs = {key: value.to(device) for key, value in inputs.items()}  # GPU kullanÄ±mÄ± iÃ§in taÅŸÄ±ma

with torch.no_grad():
    outputs = model(**inputs)

# Tahmin edilen sÄ±nÄ±f id'leri
predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()
# ROC-AUC iÃ§in, her sÄ±nÄ±fa ait olasÄ±lÄ±k skorlarÄ±nÄ± elde ediyoruz (softmax uygulanmÄ±ÅŸ Ã§Ä±ktÄ±)
y_score = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()

print(f"ğŸ“Œ GerÃ§ek etiketler (ilk 20 Ã¶rnek): {test_labels[:20]} ... (toplam {len(test_labels)} Ã¶rnek)")
print(f"ğŸ“Œ Model tahminleri (ilk 20 Ã¶rnek): {predictions[:20]} ... (toplam {len(predictions)} Ã¶rnek)")

# ========================
# 5ï¸âƒ£ Performans Metriklerinin HesaplanmasÄ±
# ========================
# Accuracy hesaplanmasÄ±
accuracy = accuracy_score(test_labels, predictions)
print(f"ğŸ”¹ Accuracy: {accuracy:.4f}")

# F1-Score hesaplanmasÄ± (weighted)
f1 = f1_score(test_labels, predictions, average="weighted")
print(f"ğŸ”¹ F1-Score: {f1:.4f}")

# Confusion Matrix oluÅŸturulmasÄ±
conf_matrix = confusion_matrix(test_labels, predictions)
print("ğŸ”¹ Confusion Matrix:")
print(conf_matrix)

# ROC-AUC HesaplamasÄ±
unique_classes = np.unique(test_labels)
if len(unique_classes) < 2:
    print("ğŸ”¹ ROC-AUC Score: HesaplanamÄ±yor. Test etiketlerinde 2'den az sÄ±nÄ±f mevcut.")
else:
    # GerÃ§ek etiketleri, test setinde bulunan sÄ±nÄ±flara gÃ¶re binarize edelim
    y_true_bin = label_binarize(test_labels, classes=unique_classes)
    # Modelin Ã§Ä±kÄ±ÅŸÄ±ndaki olasÄ±lÄ±klarÄ±n da test setinde bulunan sÄ±nÄ±flara gÃ¶re sÃ¼tunlarÄ±nÄ± seÃ§elim
    y_score_reduced = y_score[:, unique_classes]
    try:
        roc_auc = roc_auc_score(y_true_bin, y_score_reduced, multi_class="ovo")
        print(f"ğŸ”¹ ROC-AUC Score: {roc_auc:.4f}")
    except Exception as e:
        print("ğŸ”¹ ROC-AUC hesaplanÄ±rken hata oluÅŸtu:", e)
